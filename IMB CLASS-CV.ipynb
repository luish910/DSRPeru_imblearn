{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models (No Sampling) - Fitting the Train Data using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, recall_score, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=12500, n_classes=2,n_features=10, weights=[0.99, 0.01], flip_y=0, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2020,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=9900, 1=100, Test: 0=2475, 1=25\n"
     ]
    }
   ],
   "source": [
    "# Results from split\n",
    "train_0, train_1 = len(y_train[y_train==0]), len(y_train[y_train==1])\n",
    "test_0, test_1 = len(y_test[y_test==0]), len(y_test[y_test==1])\n",
    "print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CrossValidation Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold \n",
    "kf = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Logistic Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=2020)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lm = LogisticRegression(random_state = 2020)\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2474    1]\n",
      " [  13   12]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lm.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Mean Recall: 49.0, std: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "score = cross_val_score(lm, X_train, y_train, cv=kf, scoring='recall')\n",
    "print('>Mean Recall: %.1f, std: %.1f' % (score.mean()*100, score.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was K-fold accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=7920, 1=80, Test: 0=1980, 1=20\n",
      ">Train: 0=7920, 1=80, Test: 0=1980, 1=20\n",
      ">Train: 0=7920, 1=80, Test: 0=1980, 1=20\n",
      ">Train: 0=7920, 1=80, Test: 0=1980, 1=20\n",
      ">Train: 0=7920, 1=80, Test: 0=1980, 1=20\n"
     ]
    }
   ],
   "source": [
    "for train_ix, test_ix in kf.split(X_train,y_train):\n",
    "# select rows\n",
    "    train_X, test_X = X_train[train_ix], X_train[test_ix]\n",
    "    train_y, test_y = y_train[train_ix], y_train[test_ix]\n",
    "# summarize train and test composition\n",
    "    train_0, train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "    test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1])\n",
    "    print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SVM model on the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear', random_state = 0)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2474    1]\n",
      " [  16    9]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Mean Recall: 43.0, std: 6.8\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "score = cross_val_score(svm, X_train, y_train, cv=kf, scoring='recall')\n",
    "print('>Mean Recall: %.1f, std: %.1f' % (score.mean()*100, score.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Random Forest model on the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=2020)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 10\n",
    "                            , criterion= 'entropy'\n",
    "                            , random_state = 2020)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2474    1]\n",
      " [  12   13]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Mean Recall: 63.0, std: 8.7\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "score = cross_val_score(rf, X_train, y_train, cv=kf, scoring='recall')\n",
    "print('>Mean Recall: %.1f, std: %.1f' % (score.mean()*100, score.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the ANN model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.1581 - accuracy: 0.9894\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.0247 - accuracy: 0.9924\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.0231 - accuracy: 0.9945\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.0224 - accuracy: 0.9948\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 5s 470us/step - loss: 0.0221 - accuracy: 0.9945\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.0219 - accuracy: 0.9948\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.0216 - accuracy: 0.9946\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.0218 - accuracy: 0.9946\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0214 - accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 0.0215 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff029b76510>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialising the ANN\n",
    "ann = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "ann.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "ann.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "ann.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "ann.fit(X_train, y_train, batch_size = 10, epochs = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2473    2]\n",
      " [  12   13]]\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making the predictions and evaluating the model\n",
    "# Predicting the Test set results\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Mean Recall: 45.0, std: 11.4\n"
     ]
    }
   ],
   "source": [
    "#Applying Kfold CrossValidation\n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "\n",
    "score = cross_val_score(estimator=classifier, X = X_train, y = y_train, cv = kf, n_jobs = -1,scoring='recall')\n",
    "print('>Mean Recall: %.1f, std: %.1f' % (score.mean()*100, score.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
